{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934acb49-abb7-4e4c-80ea-0318b1176b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c85fdf6-021c-4eca-a034-5831d5024cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given sentences are: \n",
      " Tokenization is the first step in text analytics. The process of breaking down a text paragraph into smaller chunks such as words or sentences is called Tokenization.\n"
     ]
    }
   ],
   "source": [
    "text= \"Tokenization is the first step in text analytics. The process of breaking down a text paragraph into smaller chunks such as words or sentences is called Tokenization.\"\n",
    "print('The given sentences are: \\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250c8813-efe7-40c6-a863-5ee50091828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization is the first step in text analytics.', 'The process of breaking down a text paragraph into smaller chunks such as words or sentences is called Tokenization.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "token_text = sent_tokenize(text)\n",
    "print(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5174b1-aca3-4311-ab20-4783f77b2576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'the', 'first', 'step', 'in', 'text', 'analytics', '.', 'The', 'process', 'of', 'breaking', 'down', 'a', 'text', 'paragraph', 'into', 'smaller', 'chunks', 'such', 'as', 'words', 'or', 'sentences', 'is', 'called', 'Tokenization', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token_word = word_tokenize(text)\n",
    "print(token_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef26c28a-53a8-40c8-a2f9-464f11b193cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code for POS Tagging\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640e03c2-2c71-48f5-b3cd-8f448157d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"How to remove stop words with NLTK library in Python?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd00a76-d6c5-4166-8df8-f6544f78df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('[^A-Za-z]',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d73412-67ae-4b46-9fe9-63dc64676b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90309bc-7fe1-4d1b-a8a4-3446de46d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete text ['how', 'to', 'remove', 'stop', 'words', 'with', 'nltk', 'library', 'in', 'python']\n",
      "filtered text  ['remove', 'stop', 'words', 'nltk', 'library', 'python']\n"
     ]
    }
   ],
   "source": [
    "filterd_text=[]\n",
    "for i in tokens:\n",
    "    if i not in stop_words:\n",
    "        filterd_text.append(i)\n",
    "print(\"complete text\",tokens)\n",
    "print(\"filtered text \",filterd_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e101d09d-a6cd-4e52-aa3b-210b4f368422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steming for  eat\n",
      "steming for  eat\n",
      "steming for  eat\n",
      "steming for  wait\n",
      "steming for  wait\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "e_words =[\"eat\", \"eating\", \"eated\",\"waits\",\"waiting\"]\n",
    "ps = PorterStemmer()\n",
    "for i in e_words:\n",
    "    rootword = ps.stem(i)\n",
    "    print(\"steming for \",rootword)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9790f43-aa2d-4a9c-88a0-bd95460d8fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eating\n",
      "eated\n",
      "wait\n",
      "waiting\n",
      "study\n",
      "studing\n",
      "cry\n",
      "choot\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "words =[\"eat\", \"eating\", \"eated\",\"waits\",\"waiting\",\"study\",\"studing\",\"cries\",\"choot\"]\n",
    "lm = WordNetLemmatizer()\n",
    "for i in words:\n",
    "    rootword=lm.lemmatize(i)\n",
    "    print(rootword)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e2943c-6de9-4fc7-bd91-3379791e3702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for studies is study\n",
      "Lemma for studying is studying\n",
      "Lemma for cries is cry\n",
      "Lemma for cry is cry\n",
      "Lemma for cried is cried\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text = \"studies studying cries cry cried \"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w,\n",
    "    wordnet_lemmatizer.lemmatize(w))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b74ae1fc-c57a-455e-b393-cf88e42a24a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>can</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>see</th>\n",
       "      <th>shining</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.426858</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504235</td>\n",
       "      <td>0.321846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397544</td>\n",
       "      <td>0.321846</td>\n",
       "      <td>0.526261</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239102</td>\n",
       "      <td>0.374599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374599</td>\n",
       "      <td>0.374599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478204</td>\n",
       "      <td>0.390963</td>\n",
       "      <td>0.374599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blue    bright       can        in        is       see   shining  \\\n",
       "0  0.659191  0.000000  0.000000  0.000000  0.420753  0.000000  0.000000   \n",
       "1  0.000000  0.522109  0.000000  0.000000  0.522109  0.000000  0.000000   \n",
       "2  0.000000  0.321846  0.000000  0.504235  0.321846  0.000000  0.000000   \n",
       "3  0.000000  0.239102  0.374599  0.000000  0.000000  0.374599  0.374599   \n",
       "\n",
       "        sky       sun       the        we  \n",
       "0  0.519714  0.000000  0.343993  0.000000  \n",
       "1  0.000000  0.522109  0.426858  0.000000  \n",
       "2  0.397544  0.321846  0.526261  0.000000  \n",
       "3  0.000000  0.478204  0.390963  0.374599  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The sky is blue\",\n",
    "    \"The sun is bright\",\n",
    "    \"The sun in the sky is bright\",\n",
    "    \"We can see the shining sun, the bright sun\"\n",
    "]\n",
    "\n",
    "# Create TfidfVectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Apply TF-IDF to documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature (word) names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the matrix to a pandas DataFrame for readability\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Show TF-IDF matrix\n",
    "print(\"TF-IDF Matrix:\")\n",
    "display(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bced059-7445-4a21-9435-f5df1a89084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bright</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>see</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shining</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sky</td>\n",
       "      <td>1.510826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sun</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>we</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term       IDF\n",
       "0      blue  1.916291\n",
       "1    bright  1.223144\n",
       "2       can  1.916291\n",
       "3        in  1.916291\n",
       "4        is  1.223144\n",
       "5       see  1.916291\n",
       "6   shining  1.916291\n",
       "7       sky  1.510826\n",
       "8       sun  1.223144\n",
       "9       the  1.000000\n",
       "10       we  1.916291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get IDF values for each term\n",
    "idf_values = tfidf_vectorizer.idf_\n",
    "\n",
    "idf_df = pd.DataFrame({'Term': feature_names, 'IDF': idf_values})\n",
    "\n",
    "\n",
    "print(\"IDF values:\")\n",
    "display(idf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58a564-47c5-4c73-b908-7b89fe18470e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
